"""
Advanced Hybrid Integration System for IoT Anomaly Detection.

This module integrates all advanced algorithmic enhancements into a unified,
production-ready system that combines:

- Transformer-VAE temporal modeling
- Sparse graph attention networks
- Physics-informed neural networks
- Self-supervised registration learning
- Federated learning capabilities

Key Features:
- Modular architecture with pluggable components
- Advanced ensemble methods for improved performance
- Uncertainty quantification and interpretability
- Production-ready deployment with edge optimization
- Comprehensive monitoring and performance tracking
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, Any, Optional, List, Tuple, Union, Callable
import logging
import json
import time
from dataclasses import dataclass
from enum import Enum

from .transformer_vae import TransformerVAE, OptimizedTransformerVAE
from .sparse_graph_attention import SparseGraphAttentionNetwork
from .physics_informed_hybrid import PhysicsInformedHybridModel
from .self_supervised_registration import SelfSupervisedRegistrationLearner
from .federated_learning import FederatedClient, FederatedServer

logger = logging.getLogger(__name__)


class ModelType(Enum):
    \"\"\"Enumeration of available model types.\"\"\"\n    TRANSFORMER_VAE = \"transformer_vae\"\n    SPARSE_GAT = \"sparse_gat\"\n    PHYSICS_INFORMED = \"physics_informed\"\n    SELF_SUPERVISED = \"self_supervised\"\n    FEDERATED = \"federated\"\n    ENSEMBLE = \"ensemble\"\n\n\nclass EnsembleMethod(Enum):\n    \"\"\"Enumeration of ensemble aggregation methods.\"\"\"\n    AVERAGING = \"averaging\"\n    WEIGHTED_AVERAGING = \"weighted_averaging\"\n    STACKING = \"stacking\"\n    VOTING = \"voting\"\n    DYNAMIC_WEIGHTING = \"dynamic_weighting\"\n\n\n@dataclass\nclass ModelPrediction:\n    \"\"\"Structure for model predictions with uncertainty quantification.\"\"\"\n    anomaly_score: torch.Tensor\n    confidence: torch.Tensor\n    uncertainty: torch.Tensor\n    model_type: ModelType\n    processing_time: float\n    features: Optional[torch.Tensor] = None\n    attention_weights: Optional[torch.Tensor] = None\n    physics_constraints: Optional[Dict[str, float]] = None\n\n\n@dataclass\nclass EnsemblePrediction:\n    \"\"\"Structure for ensemble predictions.\"\"\"\n    anomaly_score: torch.Tensor\n    individual_predictions: List[ModelPrediction]\n    ensemble_confidence: torch.Tensor\n    model_weights: Dict[ModelType, float]\n    processing_time: float\n    explanation: Optional[Dict[str, Any]] = None\n\n\nclass UncertaintyQuantifier:\n    \"\"\"\n    Uncertainty quantification module for anomaly detection predictions.\n    \n    Provides both aleatoric (data) and epistemic (model) uncertainty estimates\n    for improved decision making in production environments.\n    \"\"\"\n    \n    def __init__(\n        self,\n        mc_dropout_samples: int = 10,\n        ensemble_size: int = 5,\n        temperature_scaling: bool = True\n    ):\n        self.mc_dropout_samples = mc_dropout_samples\n        self.ensemble_size = ensemble_size\n        self.temperature_scaling = temperature_scaling\n        \n        # Temperature parameter for calibration\n        self.temperature = nn.Parameter(torch.ones(1))\n    \n    def compute_mc_dropout_uncertainty(\n        self,\n        model: nn.Module,\n        x: torch.Tensor,\n        edge_index: Optional[torch.Tensor] = None\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Compute uncertainty using Monte Carlo Dropout.\n        \n        Args:\n            model: Model with dropout layers\n            x: Input tensor\n            edge_index: Optional graph connectivity\n            \n        Returns:\n            Tuple of (mean_prediction, uncertainty)\n        \"\"\"\n        model.train()  # Enable dropout\n        predictions = []\n        \n        for _ in range(self.mc_dropout_samples):\n            with torch.no_grad():\n                if edge_index is not None:\n                    pred = model(x, edge_index)\n                else:\n                    pred = model(x)\n                \n                if isinstance(pred, dict):\n                    pred = pred.get('anomaly_scores', pred.get('reconstruction', pred))\n                \n                predictions.append(pred)\n        \n        predictions = torch.stack(predictions)\n        mean_pred = predictions.mean(dim=0)\n        uncertainty = predictions.var(dim=0)\n        \n        return mean_pred, uncertainty\n    \n    def compute_ensemble_uncertainty(\n        self,\n        predictions: List[torch.Tensor]\n    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Compute uncertainty from ensemble predictions.\n        \n        Returns:\n            Tuple of (mean, aleatoric_uncertainty, epistemic_uncertainty)\n        \"\"\"\n        pred_stack = torch.stack(predictions)\n        \n        # Mean prediction\n        mean_pred = pred_stack.mean(dim=0)\n        \n        # Total uncertainty (variance of predictions)\n        total_uncertainty = pred_stack.var(dim=0)\n        \n        # Approximate decomposition\n        # Epistemic = variance of means\n        epistemic_uncertainty = total_uncertainty\n        \n        # Aleatoric = mean of individual variances (approximated as residual)\n        aleatoric_uncertainty = torch.zeros_like(epistemic_uncertainty)\n        \n        return mean_pred, aleatoric_uncertainty, epistemic_uncertainty\n    \n    def calibrate_temperature(\n        self,\n        predictions: torch.Tensor,\n        targets: torch.Tensor,\n        num_epochs: int = 100\n    ):\n        \"\"\"Calibrate temperature parameter for better confidence estimates.\"\"\"\n        optimizer = torch.optim.LBFGS([self.temperature], lr=0.01, max_iter=num_epochs)\n        \n        def closure():\n            optimizer.zero_grad()\n            calibrated_preds = predictions / self.temperature\n            loss = F.binary_cross_entropy_with_logits(calibrated_preds, targets)\n            loss.backward()\n            return loss\n        \n        optimizer.step(closure)\n        \n        logger.info(f\"Temperature calibration completed: T = {self.temperature.item():.4f}\")\n    \n    def apply_temperature_scaling(self, predictions: torch.Tensor) -> torch.Tensor:\n        \"\"\"Apply temperature scaling to calibrate confidence.\"\"\"\n        if self.temperature_scaling:\n            return predictions / self.temperature\n        return predictions\n\n\nclass ModelExplainer:\n    \"\"\"\n    Model explainability module for interpreting anomaly detection results.\n    \n    Provides various explanation methods including attention visualization,\n    feature importance, and physics-based interpretability.\n    \"\"\"\n    \n    def __init__(self):\n        self.explanation_cache = {}\n    \n    def explain_transformer_attention(\n        self,\n        model: TransformerVAE,\n        x: torch.Tensor,\n        prediction: torch.Tensor\n    ) -> Dict[str, Any]:\n        \"\"\"Generate explanations from transformer attention patterns.\"\"\"\n        # Get attention weights from transformer layers\n        with torch.no_grad():\n            outputs = model(x)\n            \n            # Extract attention patterns if available\n            attention_weights = getattr(model.encoder, 'attention_weights', None)\n            \n            if attention_weights is not None:\n                # Compute attention-based feature importance\n                feature_importance = attention_weights.mean(dim=1).mean(dim=1)\n                \n                return {\n                    'method': 'transformer_attention',\n                    'feature_importance': feature_importance.cpu().numpy(),\n                    'attention_patterns': attention_weights.cpu().numpy(),\n                    'temporal_focus': self._compute_temporal_focus(attention_weights)\n                }\n        \n        return {'method': 'transformer_attention', 'status': 'no_attention_available'}\n    \n    def explain_graph_attention(\n        self,\n        model: SparseGraphAttentionNetwork,\n        x: torch.Tensor,\n        edge_index: torch.Tensor\n    ) -> Dict[str, Any]:\n        \"\"\"Generate explanations from graph attention patterns.\"\"\"\n        with torch.no_grad():\n            outputs = model(x, edge_index)\n            \n            attention_weights = outputs.get('attention_weights')\n            \n            if attention_weights is not None:\n                edge_importance = attention_weights[1].cpu().numpy()\n                \n                return {\n                    'method': 'graph_attention',\n                    'edge_importance': edge_importance,\n                    'important_connections': self._find_important_edges(edge_index, edge_importance),\n                    'node_centrality': self._compute_node_centrality(edge_index, edge_importance)\n                }\n        \n        return {'method': 'graph_attention', 'status': 'no_attention_available'}\n    \n    def explain_physics_constraints(\n        self,\n        model: PhysicsInformedHybridModel,\n        x: torch.Tensor,\n        edge_index: torch.Tensor,\n        sensor_metadata: Dict[str, torch.Tensor]\n    ) -> Dict[str, Any]:\n        \"\"\"Generate physics-based explanations.\"\"\"\n        physics_insights = model.get_physics_insights(x, edge_index, sensor_metadata)\n        \n        return {\n            'method': 'physics_informed',\n            'constraint_violations': physics_insights['constraint_violations'],\n            'physics_interpretability': physics_insights['physics_interpretability'],\n            'anomaly_physics_correlation': self._correlate_anomalies_physics(physics_insights)\n        }\n    \n    def _compute_temporal_focus(self, attention_weights: torch.Tensor) -> Dict[str, float]:\n        \"\"\"Compute temporal focus statistics from attention patterns.\"\"\"\n        # Average attention across heads and layers\n        avg_attention = attention_weights.mean(dim=1)\n        \n        # Find peak attention positions\n        max_positions = avg_attention.argmax(dim=-1)\n        \n        return {\n            'peak_position_mean': max_positions.float().mean().item(),\n            'attention_entropy': -(avg_attention * torch.log(avg_attention + 1e-8)).sum(dim=-1).mean().item(),\n            'attention_spread': avg_attention.std(dim=-1).mean().item()\n        }\n    \n    def _find_important_edges(\n        self,\n        edge_index: torch.Tensor,\n        edge_importance: np.ndarray\n    ) -> List[Tuple[int, int, float]]:\n        \"\"\"Find most important edges based on attention weights.\"\"\"\n        important_edges = []\n        \n        for i, importance in enumerate(edge_importance):\n            if i < edge_index.size(1):\n                src, dst = edge_index[:, i].cpu().numpy()\n                important_edges.append((int(src), int(dst), float(importance)))\n        \n        # Sort by importance\n        important_edges.sort(key=lambda x: x[2], reverse=True)\n        \n        return important_edges[:10]  # Top 10 edges\n    \n    def _compute_node_centrality(\n        self,\n        edge_index: torch.Tensor,\n        edge_importance: np.ndarray\n    ) -> Dict[int, float]:\n        \"\"\"Compute node centrality based on edge importance.\"\"\"\n        node_centrality = {}\n        \n        for i, importance in enumerate(edge_importance):\n            if i < edge_index.size(1):\n                src, dst = edge_index[:, i].cpu().numpy()\n                src, dst = int(src), int(dst)\n                \n                node_centrality[src] = node_centrality.get(src, 0) + importance\n                node_centrality[dst] = node_centrality.get(dst, 0) + importance\n        \n        return node_centrality\n    \n    def _correlate_anomalies_physics(\n        self,\n        physics_insights: Dict[str, Any]\n    ) -> Dict[str, float]:\n        \"\"\"Correlate detected anomalies with physics constraint violations.\"\"\"\n        correlations = {}\n        \n        constraint_violations = physics_insights.get('constraint_violations', {})\n        \n        for constraint, violation_level in constraint_violations.items():\n            if isinstance(violation_level, (int, float)):\n                correlations[f'{constraint}_correlation'] = float(violation_level)\n        \n        return correlations\n\n\nclass AdvancedEnsembleModel:\n    \"\"\"\n    Advanced ensemble model combining multiple anomaly detection approaches.\n    \n    Implements sophisticated ensemble methods with dynamic weighting,\n    uncertainty quantification, and interpretability features.\n    \"\"\"\n    \n    def __init__(\n        self,\n        models: Dict[ModelType, nn.Module],\n        ensemble_method: EnsembleMethod = EnsembleMethod.DYNAMIC_WEIGHTING,\n        uncertainty_quantifier: Optional[UncertaintyQuantifier] = None,\n        explainer: Optional[ModelExplainer] = None\n    ):\n        self.models = models\n        self.ensemble_method = ensemble_method\n        self.uncertainty_quantifier = uncertainty_quantifier or UncertaintyQuantifier()\n        self.explainer = explainer or ModelExplainer()\n        \n        # Dynamic weighting parameters\n        self.model_weights = {model_type: 1.0 / len(models) for model_type in models.keys()}\n        self.weight_update_rate = 0.01\n        self.performance_history = {model_type: [] for model_type in models.keys()}\n        \n        # Stacking meta-learner (if using stacking ensemble)\n        if ensemble_method == EnsembleMethod.STACKING:\n            self.meta_learner = nn.Sequential(\n                nn.Linear(len(models), 32),\n                nn.ReLU(),\n                nn.Dropout(0.1),\n                nn.Linear(32, 1),\n                nn.Sigmoid()\n            )\n        \n        logger.info(f\"Initialized ensemble with {len(models)} models using {ensemble_method.value}\")\n    \n    def predict(\n        self,\n        x: torch.Tensor,\n        edge_index: Optional[torch.Tensor] = None,\n        sensor_metadata: Optional[Dict[str, torch.Tensor]] = None,\n        return_individual: bool = False,\n        return_explanations: bool = False\n    ) -> Union[EnsemblePrediction, Tuple[EnsemblePrediction, Dict[str, Any]]]:\n        \"\"\"\n        Make ensemble predictions with uncertainty quantification.\n        \n        Args:\n            x: Input tensor\n            edge_index: Optional graph connectivity\n            sensor_metadata: Optional sensor metadata for physics models\n            return_individual: Whether to return individual model predictions\n            return_explanations: Whether to generate explanations\n            \n        Returns:\n            EnsemblePrediction with optional explanations\n        \"\"\"\n        start_time = time.time()\n        individual_predictions = []\n        \n        # Get predictions from each model\n        for model_type, model in self.models.items():\n            try:\n                pred_start = time.time()\n                \n                # Forward pass based on model type\n                if model_type == ModelType.TRANSFORMER_VAE:\n                    output = model(x)\n                    anomaly_score = model.compute_anomaly_score(x)\n                    features = output.get('z', None)\n                    \n                elif model_type == ModelType.SPARSE_GAT:\n                    output = model(x, edge_index) if edge_index is not None else model(x, torch.empty(2, 0))\n                    anomaly_score = output.get('anomaly_scores', output['graph_embedding'].norm(dim=-1))\n                    features = output['graph_embedding']\n                    \n                elif model_type == ModelType.PHYSICS_INFORMED:\n                    output = model(x, edge_index, sensor_metadata)\n                    anomaly_score = output['anomaly_scores']\n                    features = output['fused_features']\n                    \n                elif model_type == ModelType.SELF_SUPERVISED:\n                    # Handle potential dimension mismatch\n                    node_features = x.mean(dim=1) if x.dim() == 3 else x\n                    if edge_index is None:\n                        edge_index = torch.empty(2, 0, dtype=torch.long, device=x.device)\n                    output = model(x, node_features, edge_index)\n                    anomaly_score = output['anomaly_scores']\n                    features = output['fused_features']\n                    \n                else:\n                    continue  # Skip unsupported model types\n                \n                # Compute uncertainty\n                if hasattr(model, 'train'):  # Check if model supports dropout\n                    _, uncertainty = self.uncertainty_quantifier.compute_mc_dropout_uncertainty(model, x, edge_index)\n                    uncertainty = uncertainty.mean() if uncertainty.dim() > 0 else uncertainty\n                else:\n                    uncertainty = torch.tensor(0.0)\n                \n                # Compute confidence (inverse of uncertainty)\n                confidence = 1.0 / (1.0 + uncertainty)\n                \n                pred_time = time.time() - pred_start\n                \n                # Create prediction object\n                prediction = ModelPrediction(\n                    anomaly_score=anomaly_score.squeeze() if anomaly_score.dim() > 1 else anomaly_score,\n                    confidence=confidence,\n                    uncertainty=uncertainty,\n                    model_type=model_type,\n                    processing_time=pred_time,\n                    features=features\n                )\n                \n                individual_predictions.append(prediction)\n                \n            except Exception as e:\n                logger.warning(f\"Error in {model_type.value} prediction: {e}\")\n                continue\n        \n        if not individual_predictions:\n            raise RuntimeError(\"No models produced valid predictions\")\n        \n        # Ensemble aggregation\n        ensemble_score, ensemble_confidence = self._aggregate_predictions(individual_predictions)\n        \n        total_time = time.time() - start_time\n        \n        # Create ensemble prediction\n        ensemble_pred = EnsemblePrediction(\n            anomaly_score=ensemble_score,\n            individual_predictions=individual_predictions if return_individual else [],\n            ensemble_confidence=ensemble_confidence,\n            model_weights=self.model_weights.copy(),\n            processing_time=total_time\n        )\n        \n        # Generate explanations if requested\n        explanations = {}\n        if return_explanations:\n            explanations = self._generate_explanations(\n                individual_predictions, x, edge_index, sensor_metadata\n            )\n            ensemble_pred.explanation = explanations\n        \n        if return_explanations:\n            return ensemble_pred, explanations\n        return ensemble_pred\n    \n    def _aggregate_predictions(\n        self,\n        predictions: List[ModelPrediction]\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Aggregate individual model predictions using the specified ensemble method.\"\"\"\n        if self.ensemble_method == EnsembleMethod.AVERAGING:\n            return self._simple_averaging(predictions)\n        elif self.ensemble_method == EnsembleMethod.WEIGHTED_AVERAGING:\n            return self._weighted_averaging(predictions)\n        elif self.ensemble_method == EnsembleMethod.DYNAMIC_WEIGHTING:\n            return self._dynamic_weighted_averaging(predictions)\n        elif self.ensemble_method == EnsembleMethod.STACKING:\n            return self._stacking_aggregation(predictions)\n        elif self.ensemble_method == EnsembleMethod.VOTING:\n            return self._voting_aggregation(predictions)\n        else:\n            return self._simple_averaging(predictions)  # Default fallback\n    \n    def _simple_averaging(self, predictions: List[ModelPrediction]) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Simple average of all predictions.\"\"\"\n        scores = torch.stack([pred.anomaly_score for pred in predictions])\n        confidences = torch.stack([pred.confidence for pred in predictions])\n        \n        avg_score = scores.mean(dim=0)\n        avg_confidence = confidences.mean(dim=0)\n        \n        return avg_score, avg_confidence\n    \n    def _weighted_averaging(self, predictions: List[ModelPrediction]) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Weighted average based on static model weights.\"\"\"\n        weighted_scores = []\n        weighted_confidences = []\n        total_weight = 0\n        \n        for pred in predictions:\n            weight = self.model_weights.get(pred.model_type, 0)\n            weighted_scores.append(pred.anomaly_score * weight)\n            weighted_confidences.append(pred.confidence * weight)\n            total_weight += weight\n        \n        if total_weight > 0:\n            avg_score = sum(weighted_scores) / total_weight\n            avg_confidence = sum(weighted_confidences) / total_weight\n        else:\n            return self._simple_averaging(predictions)\n        \n        return avg_score, avg_confidence\n    \n    def _dynamic_weighted_averaging(\n        self,\n        predictions: List[ModelPrediction]\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Dynamic weighted average based on confidence and historical performance.\"\"\"\n        dynamic_weights = []\n        \n        for pred in predictions:\n            # Base weight from static configuration\n            base_weight = self.model_weights.get(pred.model_type, 0)\n            \n            # Confidence-based adjustment\n            confidence_weight = pred.confidence.item() if hasattr(pred.confidence, 'item') else float(pred.confidence)\n            \n            # Historical performance adjustment\n            hist_perf = np.mean(self.performance_history.get(pred.model_type, [1.0])[-10:])\n            \n            # Combined dynamic weight\n            dynamic_weight = base_weight * confidence_weight * hist_perf\n            dynamic_weights.append(dynamic_weight)\n        \n        # Normalize weights\n        total_weight = sum(dynamic_weights)\n        if total_weight > 0:\n            dynamic_weights = [w / total_weight for w in dynamic_weights]\n        else:\n            dynamic_weights = [1.0 / len(predictions)] * len(predictions)\n        \n        # Weighted aggregation\n        weighted_score = sum(\n            pred.anomaly_score * weight\n            for pred, weight in zip(predictions, dynamic_weights)\n        )\n        \n        weighted_confidence = sum(\n            pred.confidence * weight\n            for pred, weight in zip(predictions, dynamic_weights)\n        )\n        \n        return weighted_score, weighted_confidence\n    \n    def _stacking_aggregation(self, predictions: List[ModelPrediction]) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Stacking ensemble using meta-learner.\"\"\"\n        if not hasattr(self, 'meta_learner'):\n            return self._simple_averaging(predictions)\n        \n        # Stack individual predictions as features for meta-learner\n        stacked_preds = torch.stack([pred.anomaly_score for pred in predictions], dim=-1)\n        \n        # Meta-learner prediction\n        with torch.no_grad():\n            ensemble_score = self.meta_learner(stacked_preds)\n        \n        # Aggregate confidences\n        avg_confidence = torch.stack([pred.confidence for pred in predictions]).mean(dim=0)\n        \n        return ensemble_score.squeeze(), avg_confidence\n    \n    def _voting_aggregation(self, predictions: List[ModelPrediction]) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Majority voting ensemble.\"\"\"\n        # Convert scores to binary votes (threshold at 0.5)\n        votes = [(pred.anomaly_score > 0.5).float() for pred in predictions]\n        \n        # Majority vote\n        vote_sum = sum(votes)\n        ensemble_score = (vote_sum > len(votes) / 2).float()\n        \n        # Confidence based on vote unanimity\n        ensemble_confidence = torch.abs(vote_sum / len(votes) - 0.5) * 2\n        \n        return ensemble_score, ensemble_confidence\n    \n    def _generate_explanations(\n        self,\n        predictions: List[ModelPrediction],\n        x: torch.Tensor,\n        edge_index: Optional[torch.Tensor],\n        sensor_metadata: Optional[Dict[str, torch.Tensor]]\n    ) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive explanations for ensemble prediction.\"\"\"\n        explanations = {'individual_explanations': {}}\n        \n        for pred in predictions:\n            model_type = pred.model_type\n            model = self.models[model_type]\n            \n            try:\n                if model_type == ModelType.TRANSFORMER_VAE:\n                    explanation = self.explainer.explain_transformer_attention(model, x, pred.anomaly_score)\n                elif model_type == ModelType.SPARSE_GAT:\n                    explanation = self.explainer.explain_graph_attention(model, x, edge_index)\n                elif model_type == ModelType.PHYSICS_INFORMED:\n                    explanation = self.explainer.explain_physics_constraints(model, x, edge_index, sensor_metadata)\n                else:\n                    explanation = {'method': model_type.value, 'status': 'no_explanation_available'}\n                \n                explanations['individual_explanations'][model_type.value] = explanation\n                \n            except Exception as e:\n                logger.warning(f\"Error generating explanation for {model_type.value}: {e}\")\n                explanations['individual_explanations'][model_type.value] = {\n                    'method': model_type.value,\n                    'status': 'explanation_failed',\n                    'error': str(e)\n                }\n        \n        # Ensemble-level explanations\n        explanations['ensemble_summary'] = {\n            'dominant_model': max(self.model_weights, key=self.model_weights.get).value,\n            'model_agreement': self._compute_model_agreement(predictions),\n            'uncertainty_sources': self._identify_uncertainty_sources(predictions)\n        }\n        \n        return explanations\n    \n    def _compute_model_agreement(self, predictions: List[ModelPrediction]) -> float:\n        \"\"\"Compute agreement level among models.\"\"\"\n        scores = [pred.anomaly_score.item() if hasattr(pred.anomaly_score, 'item') \n                 else float(pred.anomaly_score) for pred in predictions]\n        \n        if len(scores) < 2:\n            return 1.0\n        \n        # Compute coefficient of variation (std/mean)\n        mean_score = np.mean(scores)\n        std_score = np.std(scores)\n        \n        if mean_score == 0:\n            return 1.0 if std_score == 0 else 0.0\n        \n        cv = std_score / abs(mean_score)\n        agreement = 1.0 / (1.0 + cv)  # Higher agreement for lower variation\n        \n        return agreement\n    \n    def _identify_uncertainty_sources(self, predictions: List[ModelPrediction]) -> Dict[str, float]:\n        \"\"\"Identify main sources of prediction uncertainty.\"\"\"\n        uncertainty_sources = {}\n        \n        for pred in predictions:\n            model_type = pred.model_type.value\n            uncertainty_val = pred.uncertainty.item() if hasattr(pred.uncertainty, 'item') \\\n                            else float(pred.uncertainty)\n            uncertainty_sources[model_type] = uncertainty_val\n        \n        return uncertainty_sources\n    \n    def update_model_weights(\n        self,\n        predictions: List[ModelPrediction],\n        ground_truth: torch.Tensor\n    ):\n        \"\"\"Update model weights based on performance feedback.\"\"\"\n        for pred in predictions:\n            model_type = pred.model_type\n            \n            # Compute individual model performance\n            pred_score = pred.anomaly_score.item() if hasattr(pred.anomaly_score, 'item') \\\n                        else float(pred.anomaly_score)\n            gt_score = ground_truth.item() if hasattr(ground_truth, 'item') else float(ground_truth)\n            \n            # Binary accuracy\n            accuracy = 1.0 if (pred_score > 0.5) == (gt_score > 0.5) else 0.0\n            \n            # Update performance history\n            self.performance_history[model_type].append(accuracy)\n            \n            # Keep only recent history\n            if len(self.performance_history[model_type]) > 100:\n                self.performance_history[model_type] = self.performance_history[model_type][-100:]\n            \n            # Update weights based on recent performance\n            recent_performance = np.mean(self.performance_history[model_type][-10:])\n            \n            # Exponential moving average update\n            self.model_weights[model_type] = (\n                (1 - self.weight_update_rate) * self.model_weights[model_type] +\n                self.weight_update_rate * recent_performance\n            )\n        \n        # Normalize weights\n        total_weight = sum(self.model_weights.values())\n        if total_weight > 0:\n            self.model_weights = {k: v / total_weight for k, v in self.model_weights.items()}\n    \n    def get_model_summary(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive summary of ensemble model.\"\"\"\n        return {\n            'ensemble_method': self.ensemble_method.value,\n            'num_models': len(self.models),\n            'model_types': [model_type.value for model_type in self.models.keys()],\n            'current_weights': self.model_weights,\n            'performance_history': {\n                model_type.value: np.mean(hist[-10:]) if hist else 0.0\n                for model_type, hist in self.performance_history.items()\n            },\n            'uncertainty_quantification': {\n                'mc_dropout_samples': self.uncertainty_quantifier.mc_dropout_samples,\n                'temperature_scaling': self.uncertainty_quantifier.temperature_scaling\n            }\n        }\n\n\n# Factory function for creating integrated hybrid models\ndef create_advanced_hybrid_system(\n    config: Dict[str, Any]\n) -> AdvancedEnsembleModel:\n    \"\"\"\n    Factory function to create advanced hybrid anomaly detection system.\n    \n    Args:\n        config: Configuration dictionary specifying models and ensemble settings\n        \n    Returns:\n        AdvancedEnsembleModel instance\n    \"\"\"\n    models = {}\n    \n    # Create individual models based on configuration\n    if config.get('enable_transformer_vae', True):\n        from .transformer_vae import create_transformer_vae\n        models[ModelType.TRANSFORMER_VAE] = create_transformer_vae(\n            config.get('transformer_vae', {}), optimized=True\n        )\n    \n    if config.get('enable_sparse_gat', True):\n        from .sparse_graph_attention import create_sparse_gat\n        models[ModelType.SPARSE_GAT] = create_sparse_gat(\n            config.get('sparse_gat', {})\n        )\n    \n    if config.get('enable_physics_informed', True):\n        from .physics_informed_hybrid import create_physics_informed_model\n        models[ModelType.PHYSICS_INFORMED] = create_physics_informed_model(\n            config.get('physics_informed', {})\n        )\n    \n    if config.get('enable_self_supervised', True):\n        from .self_supervised_registration import create_self_supervised_learner\n        models[ModelType.SELF_SUPERVISED] = create_self_supervised_learner(\n            config.get('self_supervised', {})\n        )\n    \n    # Ensemble configuration\n    ensemble_method_str = config.get('ensemble_method', 'dynamic_weighting')\n    ensemble_method = EnsembleMethod(ensemble_method_str)\n    \n    # Uncertainty quantification\n    uncertainty_config = config.get('uncertainty_quantification', {})\n    uncertainty_quantifier = UncertaintyQuantifier(**uncertainty_config)\n    \n    # Model explainer\n    explainer = ModelExplainer()\n    \n    return AdvancedEnsembleModel(\n        models=models,\n        ensemble_method=ensemble_method,\n        uncertainty_quantifier=uncertainty_quantifier,\n        explainer=explainer\n    )