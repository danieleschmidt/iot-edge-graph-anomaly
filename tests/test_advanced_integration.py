"""
Comprehensive test suite for advanced algorithm integration.

Tests all new algorithmic enhancements including:
- Transformer-VAE temporal modeling
- Sparse graph attention networks  
- Physics-informed neural networks
- Self-supervised registration learning
- Federated learning capabilities
- Advanced ensemble integration
"""

import pytest
import torch
import torch.nn as nn
import numpy as np
import logging
from typing import Dict, Any, List, Optional
import tempfile
import os
import json

logger = logging.getLogger(__name__)

# Import all advanced models
from src.iot_edge_anomaly.models.transformer_vae import (
    TransformerVAE, OptimizedTransformerVAE, create_transformer_vae
)
from src.iot_edge_anomaly.models.sparse_graph_attention import (
    SparseGraphAttentionNetwork, create_sparse_gat
)
from src.iot_edge_anomaly.models.physics_informed_hybrid import (
    PhysicsInformedHybridModel, create_physics_informed_model
)
from src.iot_edge_anomaly.models.self_supervised_registration import (
    SelfSupervisedRegistrationLearner, create_self_supervised_learner
)
from src.iot_edge_anomaly.models.federated_learning import (
    FederatedClient, FederatedServer, create_federated_client, create_federated_server
)
from src.iot_edge_anomaly.models.advanced_hybrid_integration import (
    AdvancedEnsembleModel, ModelType, EnsembleMethod, create_advanced_hybrid_system
)


class TestTransformerVAE:\n    \"\"\"Test suite for Transformer-VAE models.\"\"\"\n    \n    @pytest.fixture\n    def sample_data(self):\n        \"\"\"Create sample time series data.\"\"\"\n        batch_size, seq_len, input_size = 4, 20, 5\n        return torch.randn(batch_size, seq_len, input_size)\n    \n    @pytest.fixture\n    def transformer_config(self):\n        \"\"\"Basic Transformer-VAE configuration.\"\"\"\n        return {\n            'input_size': 5,\n            'd_model': 64,\n            'num_layers': 2,\n            'num_heads': 4,\n            'latent_dim': 16,\n            'max_seq_len': 50\n        }\n    \n    def test_transformer_vae_creation(self, transformer_config):\n        \"\"\"Test TransformerVAE model creation.\"\"\"\n        model = create_transformer_vae(transformer_config, optimized=False)\n        assert isinstance(model, TransformerVAE)\n        assert model.input_size == 5\n        assert model.latent_dim == 16\n    \n    def test_optimized_transformer_vae_creation(self, transformer_config):\n        \"\"\"Test OptimizedTransformerVAE model creation.\"\"\"\n        model = create_transformer_vae(transformer_config, optimized=True)\n        assert isinstance(model, OptimizedTransformerVAE)\n        assert model.input_size == 5\n        assert model.latent_dim == 16\n    \n    def test_transformer_vae_forward_pass(self, sample_data, transformer_config):\n        \"\"\"Test forward pass through TransformerVAE.\"\"\"\n        model = create_transformer_vae(transformer_config)\n        model.eval()\n        \n        with torch.no_grad():\n            outputs = model(sample_data)\n        \n        assert 'reconstruction' in outputs\n        assert 'z' in outputs\n        assert 'mu' in outputs\n        assert 'logvar' in outputs\n        \n        assert outputs['reconstruction'].shape == sample_data.shape\n        assert outputs['z'].shape == (sample_data.size(0), model.latent_dim)\n    \n    def test_transformer_vae_anomaly_scoring(self, sample_data, transformer_config):\n        \"\"\"Test anomaly score computation.\"\"\"\n        model = create_transformer_vae(transformer_config)\n        model.eval()\n        \n        with torch.no_grad():\n            anomaly_scores = model.compute_anomaly_score(sample_data)\n        \n        assert anomaly_scores.shape == (sample_data.size(0),)\n        assert torch.all(anomaly_scores >= 0)\n    \n    def test_transformer_vae_loss_computation(self, sample_data, transformer_config):\n        \"\"\"Test VAE loss computation.\"\"\"\n        model = create_transformer_vae(transformer_config)\n        losses = model.compute_loss(sample_data)\n        \n        assert 'total_loss' in losses\n        assert 'recon_loss' in losses\n        assert 'kl_loss' in losses\n        \n        assert torch.all(losses['total_loss'] >= 0)\n        assert torch.all(losses['recon_loss'] >= 0)\n        assert torch.all(losses['kl_loss'] >= 0)\n    \n    def test_transformer_vae_quantization(self, transformer_config):\n        \"\"\"Test model quantization for edge deployment.\"\"\"\n        model = create_transformer_vae(transformer_config, optimized=True)\n        \n        # Test quantization\n        quantized_model = model.quantize_model()\n        assert quantized_model is not None\n\n\nclass TestSparseGraphAttention:\n    \"\"\"Test suite for Sparse Graph Attention Networks.\"\"\"\n    \n    @pytest.fixture\n    def graph_data(self):\n        \"\"\"Create sample graph data.\"\"\"\n        num_nodes, input_dim = 10, 32\n        x = torch.randn(num_nodes, input_dim)\n        \n        # Create random graph connectivity\n        num_edges = 20\n        edge_index = torch.randint(0, num_nodes, (2, num_edges))\n        \n        return x, edge_index\n    \n    @pytest.fixture\n    def sparse_gat_config(self):\n        \"\"\"Sparse GAT configuration.\"\"\"\n        return {\n            'input_dim': 32,\n            'hidden_dim': 64,\n            'output_dim': 32,\n            'num_layers': 2,\n            'num_heads': 4,\n            'sparsity_factor': 0.2,\n            'adaptive_sparsity': True\n        }\n    \n    def test_sparse_gat_creation(self, sparse_gat_config):\n        \"\"\"Test Sparse GAT model creation.\"\"\"\n        model = create_sparse_gat(sparse_gat_config)\n        assert isinstance(model, SparseGraphAttentionNetwork)\n        assert model.input_dim == 32\n        assert model.output_dim == 32\n    \n    def test_sparse_gat_forward_pass(self, graph_data, sparse_gat_config):\n        \"\"\"Test forward pass through Sparse GAT.\"\"\"\n        x, edge_index = graph_data\n        model = create_sparse_gat(sparse_gat_config)\n        model.eval()\n        \n        with torch.no_grad():\n            outputs = model(x, edge_index)\n        \n        assert 'node_features' in outputs\n        assert 'graph_embedding' in outputs\n        assert 'attention_weights' in outputs\n        \n        assert outputs['node_features'].shape == (x.size(0), model.output_dim)\n        assert outputs['graph_embedding'].shape[1] == model.output_dim\n    \n    def test_sparse_attention_complexity(self, sparse_gat_config):\n        \"\"\"Test sparse attention complexity reduction.\"\"\"\n        model = create_sparse_gat(sparse_gat_config)\n        stats = model.get_complexity_stats()\n        \n        assert 'total_parameters' in stats\n        assert 'estimated_complexity_reduction' in stats\n        assert stats['estimated_complexity_reduction'] > 0\n        assert stats['adaptive_sparsity_enabled'] == True\n    \n    def test_dynamic_topology_learning(self, graph_data, sparse_gat_config):\n        \"\"\"Test dynamic graph topology learning.\"\"\"\n        x, edge_index = graph_data\n        sparse_gat_config['learn_topology'] = True\n        model = create_sparse_gat(sparse_gat_config)\n        model.eval()\n        \n        with torch.no_grad():\n            outputs = model(x, edge_index)\n        \n        learned_topology = outputs['learned_topology']\n        if learned_topology is not None:\n            assert 'edge_index' in learned_topology\n            assert 'edge_weights' in learned_topology\n\n\nclass TestPhysicsInformedHybrid:\n    \"\"\"Test suite for Physics-Informed Hybrid Models.\"\"\"\n    \n    @pytest.fixture\n    def physics_data(self):\n        \"\"\"Create sample data with physics variables.\"\"\"\n        batch_size, seq_len, input_size = 4, 20, 5\n        x = torch.randn(batch_size, seq_len, input_size)\n        \n        # Create sample sensor metadata for physics constraints\n        sensor_data = {\n            'flow_in': torch.abs(torch.randn(batch_size, seq_len)),\n            'flow_out': torch.abs(torch.randn(batch_size, seq_len)),\n            'level': torch.abs(torch.randn(batch_size, seq_len)),\n            'temperature': torch.randn(batch_size, seq_len) + 20,\n            'pressure_up': torch.abs(torch.randn(batch_size, seq_len)) + 10,\n            'pressure_down': torch.abs(torch.randn(batch_size, seq_len)) + 5\n        }\n        \n        edge_index = torch.randint(0, 4, (2, 8))  # Simple graph connectivity\n        \n        return x, edge_index, sensor_data\n    \n    @pytest.fixture\n    def physics_config(self):\n        \"\"\"Physics-informed model configuration.\"\"\"\n        return {\n            'input_size': 5,\n            'hidden_size': 64,\n            'lstm_layers': 2,\n            'gnn_layers': 2,\n            'latent_dim': 32,\n            'use_transformer': True,\n            'use_sparse_attention': True,\n            'constraint_config': {\n                'weights': {\n                    'mass_conservation': 1.0,\n                    'energy_conservation': 0.5,\n                    'pressure_drop': 0.5\n                },\n                'adaptive_weighting': True,\n                'tolerance': 0.01\n            }\n        }\n    \n    def test_physics_informed_creation(self, physics_config):\n        \"\"\"Test physics-informed model creation.\"\"\"\n        model = create_physics_informed_model(physics_config)\n        assert isinstance(model, PhysicsInformedHybridModel)\n        assert model.input_size == 5\n        assert model.latent_dim == 32\n    \n    def test_physics_informed_forward_pass(self, physics_data, physics_config):\n        \"\"\"Test forward pass with physics constraints.\"\"\"\n        x, edge_index, sensor_metadata = physics_data\n        model = create_physics_informed_model(physics_config)\n        model.eval()\n        \n        with torch.no_grad():\n            outputs = model(x, edge_index, sensor_metadata)\n        \n        assert 'anomaly_scores' in outputs\n        assert 'temporal_features' in outputs\n        assert 'spatial_features' in outputs\n        assert 'fused_features' in outputs\n        \n        assert outputs['anomaly_scores'].shape == (x.size(0), 1)\n    \n    def test_physics_constraints_validation(self, physics_data, physics_config):\n        \"\"\"Test physics constraints validation.\"\"\"\n        x, edge_index, sensor_metadata = physics_data\n        model = create_physics_informed_model(physics_config)\n        \n        violations = model.validate_physics_constraints(sensor_metadata)\n        assert isinstance(violations, dict)\n        # Should contain some constraint violations\n        assert len(violations) >= 0\n    \n    def test_physics_informed_loss(self, physics_data, physics_config):\n        \"\"\"Test physics-informed loss computation.\"\"\"\n        x, edge_index, sensor_metadata = physics_data\n        model = create_physics_informed_model(physics_config)\n        \n        # Forward pass to get predictions\n        outputs = model(x, edge_index, sensor_metadata)\n        predictions = outputs['anomaly_scores']\n        targets = torch.rand_like(predictions)\n        \n        # Compute physics-informed loss\n        loss_dict = model.compute_physics_informed_loss(\n            predictions, targets, sensor_metadata\n        )\n        \n        assert 'total_loss' in loss_dict\n        assert 'data_loss' in loss_dict\n        assert 'constraint_loss' in loss_dict\n        \n        assert torch.all(loss_dict['total_loss'] >= 0)\n    \n    def test_physics_insights(self, physics_data, physics_config):\n        \"\"\"Test physics-based insights generation.\"\"\"\n        x, edge_index, sensor_metadata = physics_data\n        model = create_physics_informed_model(physics_config)\n        \n        insights = model.get_physics_insights(x, edge_index, sensor_metadata)\n        \n        assert 'constraint_violations' in insights\n        assert 'anomaly_scores' in insights\n        assert isinstance(insights['constraint_violations'], dict)\n\n\nclass TestSelfSupervisedRegistration:\n    \"\"\"Test suite for Self-Supervised Registration Learning.\"\"\"\n    \n    @pytest.fixture\n    def registration_data(self):\n        \"\"\"Create sample data for registration learning.\"\"\"\n        batch_size, seq_len, input_dim = 4, 30, 5\n        temporal_data = torch.randn(batch_size, seq_len, input_dim)\n        \n        num_nodes = 8\n        node_features = torch.randn(num_nodes, 32)\n        edge_index = torch.randint(0, num_nodes, (2, 12))\n        \n        return temporal_data, node_features, edge_index\n    \n    @pytest.fixture\n    def registration_config(self):\n        \"\"\"Self-supervised registration configuration.\"\"\"\n        return {\n            'input_dim': 5,\n            'node_feature_dim': 32,\n            'hidden_dim': 64,\n            'temporal_layers': 2,\n            'spatial_layers': 2,\n            'dropout': 0.1,\n            'contrastive_temperature': 0.1\n        }\n    \n    def test_registration_learner_creation(self, registration_config):\n        \"\"\"Test self-supervised registration learner creation.\"\"\"\n        model = create_self_supervised_learner(registration_config)\n        assert isinstance(model, SelfSupervisedRegistrationLearner)\n        assert model.input_dim == 5\n        assert model.hidden_dim == 64\n    \n    def test_registration_forward_pass(self, registration_data, registration_config):\n        \"\"\"Test forward pass through registration learner.\"\"\"\n        temporal_data, node_features, edge_index = registration_data\n        model = create_self_supervised_learner(registration_config)\n        model.eval()\n        \n        with torch.no_grad():\n            outputs = model(temporal_data, node_features, edge_index)\n        \n        assert 'anomaly_scores' in outputs\n        assert 'fused_features' in outputs\n        assert 'temporal_features' in outputs\n        assert 'spatial_features' in outputs\n        \n        assert outputs['anomaly_scores'].shape == (temporal_data.size(0), 1)\n    \n    def test_temporal_registration(self, registration_data, registration_config):\n        \"\"\"Test temporal registration mechanism.\"\"\"\n        temporal_data, _, _ = registration_data\n        model = create_self_supervised_learner(registration_config)\n        \n        # Test temporal shift application\n        original, shifted, shift_amount = model.temporal_registration.apply_temporal_shift(\n            temporal_data, shift_range=(-5, 5)\n        )\n        \n        assert original.shape == temporal_data.shape\n        assert shifted.shape == temporal_data.shape\n        assert isinstance(shift_amount, int)\n        assert -5 <= shift_amount <= 5\n    \n    def test_spatial_registration(self, registration_data, registration_config):\n        \"\"\"Test spatial registration with graph augmentation.\"\"\"\n        _, node_features, edge_index = registration_data\n        model = create_self_supervised_learner(registration_config)\n        \n        # Test spatial augmentation\n        aug_features, aug_edge_index = model.spatial_registration.apply_spatial_augmentation(\n            node_features, edge_index, 'dropout'\n        )\n        \n        assert aug_features.shape == node_features.shape\n        assert aug_edge_index.shape == edge_index.shape\n    \n    def test_pretraining_simulation(self, registration_data, registration_config):\n        \"\"\"Test self-supervised pretraining (short simulation).\"\"\"\n        temporal_data, node_features, edge_index = registration_data\n        model = create_self_supervised_learner(registration_config)\n        \n        # Run short pretraining simulation\n        history = model.pretrain_with_registration(\n            temporal_data, node_features, edge_index, num_epochs=2\n        )\n        \n        assert 'temporal_loss' in history\n        assert 'spatial_loss' in history\n        assert 'contrastive_loss' in history\n        \n        assert len(history['temporal_loss']) == 2\n        assert len(history['spatial_loss']) == 2\n        assert len(history['contrastive_loss']) == 2\n    \n    def test_few_shot_adaptation(self, registration_data, registration_config):\n        \"\"\"Test few-shot adaptation with limited labeled data.\"\"\"\n        temporal_data, node_features, edge_index = registration_data\n        model = create_self_supervised_learner(registration_config)\n        \n        # Create limited labeled support data\n        support_data = {\n            'temporal_data': temporal_data[:2],\n            'node_features': node_features,\n            'edge_index': edge_index\n        }\n        support_labels = torch.tensor([0, 1])  # Normal, anomaly\n        \n        # Test few-shot adaptation\n        model.few_shot_adaptation(\n            support_data, support_labels, num_adaptation_steps=2\n        )\n        \n        # Test prototype-based prediction\n        with torch.no_grad():\n            anomaly_scores = model.predict_with_prototypes(\n                temporal_data, node_features, edge_index\n            )\n        \n        assert anomaly_scores.shape == (temporal_data.size(0),)\n        assert torch.all((anomaly_scores >= 0) & (anomaly_scores <= 1))\n\n\nclass TestFederatedLearning:\n    \"\"\"Test suite for Federated Learning capabilities.\"\"\"\n    \n    @pytest.fixture\n    def federated_config(self):\n        \"\"\"Federated learning configuration.\"\"\"\n        return {\n            'model': {\n                'type': 'lstm_gnn',\n                'input_size': 5,\n                'hidden_size': 32,\n                'output_size': 16\n            },\n            'data': {\n                'batch_size': 4,\n                'num_samples': 100\n            },\n            'privacy': {\n                'epsilon': 1.0,\n                'delta': 1e-5,\n                'mechanism': 'gaussian'\n            }\n        }\n    \n    @pytest.fixture\n    def federated_data(self):\n        \"\"\"Sample federated learning data.\"\"\"\n        batch_size, seq_len, input_size = 4, 20, 5\n        \n        return {\n            'x': torch.randn(batch_size, seq_len, input_size),\n            'y': torch.randint(0, 2, (batch_size,)).float(),\n            'edge_index': torch.randint(0, batch_size, (2, 8))\n        }\n    \n    def test_federated_client_creation(self, federated_config):\n        \"\"\"Test federated client creation.\"\"\"\n        client = create_federated_client('client_1', federated_config)\n        assert isinstance(client, FederatedClient)\n        assert client.client_id == 'client_1'\n        assert client.dp_mechanism is not None\n    \n    def test_federated_server_creation(self, federated_config):\n        \"\"\"Test federated server creation.\"\"\"\n        server_config = {\n            'global_model': federated_config['model'],\n            'aggregation': {'method': 'fedavg'},\n            'security': {'secure_aggregation': False}\n        }\n        \n        server = create_federated_server(server_config)\n        assert isinstance(server, FederatedServer)\n    \n    def test_federated_client_training(self, federated_config, federated_data):\n        \"\"\"Test local training on federated client.\"\"\"\n        client = create_federated_client('client_1', federated_config)\n        \n        # Test local training\n        results = client.local_train(\n            local_data=federated_data,\n            num_epochs=2\n        )\n        \n        assert 'client_id' in results\n        assert 'model_update' in results\n        assert 'loss' in results\n        assert 'num_samples' in results\n        assert 'privacy_cost' in results\n        \n        assert results['client_id'] == 'client_1'\n        assert isinstance(results['model_update'], dict)\n        assert results['loss'] >= 0\n    \n    def test_federated_aggregation_simulation(self, federated_config, federated_data):\n        \"\"\"Test federated aggregation simulation.\"\"\"\n        # Create server\n        server_config = {\n            'global_model': federated_config['model'],\n            'aggregation': {'method': 'fedavg'},\n            'security': {'secure_aggregation': False}\n        }\n        server = create_federated_server(server_config)\n        \n        # Create multiple clients\n        clients = [\n            create_federated_client(f'client_{i}', federated_config)\n            for i in range(3)\n        ]\n        \n        # Simulate federated training round\n        client_updates = []\n        global_state = server.get_global_model_state()\n        \n        for client in clients:\n            update = client.local_train(\n                local_data=federated_data,\n                num_epochs=1,\n                global_model_state=global_state\n            )\n            client_updates.append(update)\n        \n        # Server aggregation\n        round_results = server.federated_training_round(client_updates, round_num=1)\n        \n        assert 'round' in round_results\n        assert 'global_model_state' in round_results\n        assert 'avg_loss' in round_results\n        assert 'num_participants' in round_results\n        \n        assert round_results['round'] == 1\n        assert round_results['num_participants'] == 3\n        assert round_results['avg_loss'] >= 0\n    \n    def test_privacy_mechanisms(self, federated_config):\n        \"\"\"Test differential privacy mechanisms.\"\"\"\n        client = create_federated_client('client_1', federated_config)\n        \n        # Test privacy cost computation\n        privacy_cost = client._compute_privacy_cost()\n        assert isinstance(privacy_cost, tuple)\n        assert len(privacy_cost) == 2  # (epsilon, delta)\n        assert privacy_cost[0] >= 0  # epsilon\n        assert privacy_cost[1] >= 0  # delta\n\n\nclass TestAdvancedIntegration:\n    \"\"\"Test suite for Advanced Hybrid Integration System.\"\"\"\n    \n    @pytest.fixture\n    def integration_config(self):\n        \"\"\"Advanced integration configuration.\"\"\"\n        return {\n            'enable_transformer_vae': True,\n            'enable_sparse_gat': True,\n            'enable_physics_informed': True,\n            'enable_self_supervised': True,\n            'ensemble_method': 'dynamic_weighting',\n            'transformer_vae': {\n                'input_size': 5,\n                'd_model': 32,\n                'num_layers': 2,\n                'latent_dim': 16\n            },\n            'sparse_gat': {\n                'input_dim': 16,\n                'hidden_dim': 32,\n                'output_dim': 16,\n                'num_layers': 2\n            },\n            'physics_informed': {\n                'input_size': 5,\n                'hidden_size': 32,\n                'latent_dim': 16,\n                'constraint_config': {\n                    'weights': {'mass_conservation': 1.0}\n                }\n            },\n            'self_supervised': {\n                'input_dim': 5,\n                'node_feature_dim': 16,\n                'hidden_dim': 32\n            },\n            'uncertainty_quantification': {\n                'mc_dropout_samples': 5,\n                'temperature_scaling': True\n            }\n        }\n    \n    @pytest.fixture\n    def integration_data(self):\n        \"\"\"Sample data for integration testing.\"\"\"\n        batch_size, seq_len, input_size = 2, 15, 5\n        x = torch.randn(batch_size, seq_len, input_size)\n        \n        num_nodes = 6\n        edge_index = torch.randint(0, num_nodes, (2, 8))\n        \n        sensor_metadata = {\n            'flow_in': torch.abs(torch.randn(batch_size, seq_len)),\n            'flow_out': torch.abs(torch.randn(batch_size, seq_len)),\n            'level': torch.abs(torch.randn(batch_size, seq_len))\n        }\n        \n        return x, edge_index, sensor_metadata\n    \n    def test_advanced_ensemble_creation(self, integration_config):\n        \"\"\"Test advanced ensemble model creation.\"\"\"\n        ensemble = create_advanced_hybrid_system(integration_config)\n        assert isinstance(ensemble, AdvancedEnsembleModel)\n        \n        # Check that models were created\n        assert ModelType.TRANSFORMER_VAE in ensemble.models\n        assert ModelType.SPARSE_GAT in ensemble.models\n        assert ModelType.PHYSICS_INFORMED in ensemble.models\n        assert ModelType.SELF_SUPERVISED in ensemble.models\n        \n        # Check ensemble configuration\n        assert ensemble.ensemble_method == EnsembleMethod.DYNAMIC_WEIGHTING\n        assert ensemble.uncertainty_quantifier is not None\n        assert ensemble.explainer is not None\n    \n    def test_ensemble_prediction(self, integration_config, integration_data):\n        \"\"\"Test ensemble prediction with all models.\"\"\"\n        x, edge_index, sensor_metadata = integration_data\n        ensemble = create_advanced_hybrid_system(integration_config)\n        \n        # Make ensemble prediction\n        with torch.no_grad():\n            prediction = ensemble.predict(\n                x, edge_index, sensor_metadata,\n                return_individual=True,\n                return_explanations=False\n            )\n        \n        assert hasattr(prediction, 'anomaly_score')\n        assert hasattr(prediction, 'ensemble_confidence')\n        assert hasattr(prediction, 'individual_predictions')\n        assert hasattr(prediction, 'model_weights')\n        assert hasattr(prediction, 'processing_time')\n        \n        # Check individual predictions\n        assert len(prediction.individual_predictions) > 0\n        for individual_pred in prediction.individual_predictions:\n            assert hasattr(individual_pred, 'anomaly_score')\n            assert hasattr(individual_pred, 'confidence')\n            assert hasattr(individual_pred, 'model_type')\n    \n    def test_ensemble_with_explanations(self, integration_config, integration_data):\n        \"\"\"Test ensemble prediction with explanations.\"\"\"\n        x, edge_index, sensor_metadata = integration_data\n        ensemble = create_advanced_hybrid_system(integration_config)\n        \n        # Make prediction with explanations\n        with torch.no_grad():\n            prediction, explanations = ensemble.predict(\n                x, edge_index, sensor_metadata,\n                return_individual=True,\n                return_explanations=True\n            )\n        \n        assert explanations is not None\n        assert 'individual_explanations' in explanations\n        assert 'ensemble_summary' in explanations\n        \n        # Check explanation structure\n        ensemble_summary = explanations['ensemble_summary']\n        assert 'dominant_model' in ensemble_summary\n        assert 'model_agreement' in ensemble_summary\n        assert 'uncertainty_sources' in ensemble_summary\n    \n    def test_uncertainty_quantification(self, integration_config, integration_data):\n        \"\"\"Test uncertainty quantification capabilities.\"\"\"\n        x, edge_index, sensor_metadata = integration_data\n        ensemble = create_advanced_hybrid_system(integration_config)\n        \n        # Get prediction with uncertainty\n        with torch.no_grad():\n            prediction = ensemble.predict(x, edge_index, sensor_metadata)\n        \n        # Check uncertainty information\n        assert hasattr(prediction, 'ensemble_confidence')\n        assert torch.all((prediction.ensemble_confidence >= 0) & (prediction.ensemble_confidence <= 1))\n        \n        # Check individual uncertainties\n        for individual_pred in prediction.individual_predictions:\n            assert hasattr(individual_pred, 'uncertainty')\n            assert torch.all(individual_pred.uncertainty >= 0)\n    \n    def test_dynamic_weight_updating(self, integration_config, integration_data):\n        \"\"\"Test dynamic model weight updating.\"\"\"\n        x, edge_index, sensor_metadata = integration_data\n        ensemble = create_advanced_hybrid_system(integration_config)\n        \n        # Get initial weights\n        initial_weights = ensemble.model_weights.copy()\n        \n        # Make prediction\n        with torch.no_grad():\n            prediction = ensemble.predict(x, edge_index, sensor_metadata)\n        \n        # Simulate ground truth and update weights\n        ground_truth = torch.tensor([1.0, 0.0])  # Binary labels\n        ensemble.update_model_weights(prediction.individual_predictions, ground_truth)\n        \n        # Check that weights were updated\n        updated_weights = ensemble.model_weights\n        \n        # At least some weights should have changed (unless by coincidence)\n        weights_changed = any(\n            abs(initial_weights[k] - updated_weights[k]) > 1e-6\n            for k in initial_weights.keys()\n        )\n        # Note: This might occasionally fail due to randomness, but should generally pass\n    \n    def test_ensemble_model_summary(self, integration_config):\n        \"\"\"Test ensemble model summary generation.\"\"\"\n        ensemble = create_advanced_hybrid_system(integration_config)\n        summary = ensemble.get_model_summary()\n        \n        assert 'ensemble_method' in summary\n        assert 'num_models' in summary\n        assert 'model_types' in summary\n        assert 'current_weights' in summary\n        assert 'performance_history' in summary\n        assert 'uncertainty_quantification' in summary\n        \n        assert summary['ensemble_method'] == 'dynamic_weighting'\n        assert summary['num_models'] > 0\n        assert len(summary['model_types']) > 0\n    \n    def test_different_ensemble_methods(self, integration_config, integration_data):\n        \"\"\"Test different ensemble aggregation methods.\"\"\"\n        x, edge_index, sensor_metadata = integration_data\n        \n        ensemble_methods = [\n            'averaging',\n            'weighted_averaging',\n            'dynamic_weighting',\n            'voting'\n        ]\n        \n        for method in ensemble_methods:\n            config = integration_config.copy()\n            config['ensemble_method'] = method\n            \n            ensemble = create_advanced_hybrid_system(config)\n            \n            # Make prediction\n            with torch.no_grad():\n                prediction = ensemble.predict(x, edge_index, sensor_metadata)\n            \n            # Check that prediction is valid\n            assert hasattr(prediction, 'anomaly_score')\n            assert prediction.anomaly_score.shape == (x.size(0),)\n    \n    @pytest.mark.parametrize('enable_model', [\n        'enable_transformer_vae',\n        'enable_sparse_gat', \n        'enable_physics_informed',\n        'enable_self_supervised'\n    ])\n    def test_individual_model_enabling(self, integration_config, integration_data, enable_model):\n        \"\"\"Test enabling individual models in the ensemble.\"\"\"\n        x, edge_index, sensor_metadata = integration_data\n        \n        # Enable only one model type\n        config = {key: False for key in integration_config.keys() if key.startswith('enable_')}\n        config.update(integration_config)\n        config[enable_model] = True\n        \n        ensemble = create_advanced_hybrid_system(config)\n        \n        # Should have exactly one model\n        assert len(ensemble.models) == 1\n        \n        # Make prediction\n        with torch.no_grad():\n            prediction = ensemble.predict(x, edge_index, sensor_metadata)\n        \n        # Check prediction validity\n        assert hasattr(prediction, 'anomaly_score')\n        assert prediction.anomaly_score.shape == (x.size(0),)\n\n\n@pytest.mark.integration\nclass TestSystemIntegration:\n    \"\"\"End-to-end integration tests.\"\"\"\n    \n    def test_full_pipeline_simulation(self):\n        \"\"\"Test complete anomaly detection pipeline.\"\"\"\n        # Configuration for full system\n        config = {\n            'enable_transformer_vae': True,\n            'enable_sparse_gat': True,\n            'enable_physics_informed': True,\n            'ensemble_method': 'dynamic_weighting',\n            'transformer_vae': {\n                'input_size': 5,\n                'd_model': 64,\n                'num_layers': 2,\n                'latent_dim': 32\n            },\n            'sparse_gat': {\n                'input_dim': 32,\n                'hidden_dim': 64,\n                'output_dim': 32,\n                'num_layers': 2\n            },\n            'physics_informed': {\n                'input_size': 5,\n                'hidden_size': 64,\n                'latent_dim': 32\n            }\n        }\n        \n        # Create ensemble system\n        ensemble = create_advanced_hybrid_system(config)\n        \n        # Simulate sensor data\n        batch_size, seq_len, input_size = 8, 25, 5\n        sensor_data = torch.randn(batch_size, seq_len, input_size)\n        edge_index = torch.randint(0, 6, (2, 12))\n        \n        sensor_metadata = {\n            'flow_in': torch.abs(torch.randn(batch_size, seq_len)),\n            'flow_out': torch.abs(torch.randn(batch_size, seq_len)),\n            'level': torch.abs(torch.randn(batch_size, seq_len))\n        }\n        \n        # Run full pipeline\n        with torch.no_grad():\n            prediction, explanations = ensemble.predict(\n                sensor_data, edge_index, sensor_metadata,\n                return_individual=True,\n                return_explanations=True\n            )\n        \n        # Validate results\n        assert prediction.anomaly_score.shape == (batch_size,)\n        assert torch.all((prediction.anomaly_score >= 0) & (prediction.anomaly_score <= 1))\n        assert len(prediction.individual_predictions) >= 2  # At least 2 models enabled\n        assert explanations is not None\n        assert prediction.processing_time > 0\n        \n        # Test model summary\n        summary = ensemble.get_model_summary()\n        assert summary['num_models'] >= 2\n        \n        logger.info(f\"Full pipeline test completed successfully\")\n        logger.info(f\"Ensemble summary: {summary}\")\n    \n    def test_performance_benchmarking(self):\n        \"\"\"Test performance benchmarking of different model combinations.\"\"\"\n        model_combinations = [\n            ['enable_transformer_vae'],\n            ['enable_sparse_gat'],\n            ['enable_physics_informed'],\n            ['enable_transformer_vae', 'enable_sparse_gat'],\n            ['enable_transformer_vae', 'enable_physics_informed'],\n            ['enable_sparse_gat', 'enable_physics_informed'],\n            ['enable_transformer_vae', 'enable_sparse_gat', 'enable_physics_informed']\n        ]\n        \n        # Test data\n        batch_size, seq_len, input_size = 4, 20, 5\n        x = torch.randn(batch_size, seq_len, input_size)\n        edge_index = torch.randint(0, 4, (2, 6))\n        sensor_metadata = {\n            'flow_in': torch.abs(torch.randn(batch_size, seq_len)),\n            'flow_out': torch.abs(torch.randn(batch_size, seq_len)),\n            'level': torch.abs(torch.randn(batch_size, seq_len))\n        }\n        \n        performance_results = []\n        \n        for combination in model_combinations:\n            # Create configuration\n            config = {\n                'enable_transformer_vae': 'enable_transformer_vae' in combination,\n                'enable_sparse_gat': 'enable_sparse_gat' in combination,\n                'enable_physics_informed': 'enable_physics_informed' in combination,\n                'enable_self_supervised': False,  # Skip for performance test\n                'ensemble_method': 'averaging',\n                'transformer_vae': {\n                    'input_size': 5, 'd_model': 32, 'num_layers': 1, 'latent_dim': 16\n                },\n                'sparse_gat': {\n                    'input_dim': 16, 'hidden_dim': 32, 'output_dim': 16, 'num_layers': 1\n                },\n                'physics_informed': {\n                    'input_size': 5, 'hidden_size': 32, 'latent_dim': 16\n                }\n            }\n            \n            try:\n                # Create ensemble\n                ensemble = create_advanced_hybrid_system(config)\n                \n                # Measure performance\n                import time\n                start_time = time.time()\n                \n                with torch.no_grad():\n                    prediction = ensemble.predict(x, edge_index, sensor_metadata)\n                \n                end_time = time.time()\n                inference_time = end_time - start_time\n                \n                performance_results.append({\n                    'combination': combination,\n                    'num_models': len(ensemble.models),\n                    'inference_time': inference_time,\n                    'avg_anomaly_score': prediction.anomaly_score.mean().item()\n                })\n                \n            except Exception as e:\n                logger.warning(f\"Failed combination {combination}: {e}\")\n                continue\n        \n        # Validate that we got results\n        assert len(performance_results) > 0\n        \n        # Log performance results\n        for result in performance_results:\n            logger.info(f\"Combination {result['combination']}: \"\n                       f\"{result['num_models']} models, \"\n                       f\"{result['inference_time']:.4f}s inference time\")\n        \n        # Check that more models generally take longer (with some tolerance)\n        single_model_times = [r['inference_time'] for r in performance_results if r['num_models'] == 1]\n        multi_model_times = [r['inference_time'] for r in performance_results if r['num_models'] > 1]\n        \n        if single_model_times and multi_model_times:\n            avg_single = np.mean(single_model_times)\n            avg_multi = np.mean(multi_model_times)\n            logger.info(f\"Average single model time: {avg_single:.4f}s\")\n            logger.info(f\"Average multi model time: {avg_multi:.4f}s\")\n\n\nif __name__ == \"__main__\":\n    # Run tests if script is executed directly\n    pytest.main([__file__, \"-v\", \"-s\"])